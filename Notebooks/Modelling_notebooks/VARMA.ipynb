{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6392a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.api import VARMAX \n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a63cb",
   "metadata": {},
   "source": [
    "# VARMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedcde6",
   "metadata": {},
   "source": [
    "<b>Referes to</b> \n",
    "<ul>\n",
    "    <li><a>https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/ </a></li>\n",
    "    <li><a>https://youtu.be/7_Js8h709Dw</a></li>\n",
    "    <li><a>https://youtu.be/6Ye0CsfRDJg</a></li>\n",
    "    <li><a>https://www.statsmodels.org/stable/examples/notebooks/generated/statespace_varmax.html#Caution:-VARMA(p,q)-specifications</a></li>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7e7c8",
   "metadata": {},
   "source": [
    "Stands for Vector Autoregressive Intergrated Moving average <br>\n",
    "\n",
    "This acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n",
    "<ul>\n",
    "    <li><b>V:</b> Vector. Allows for multiple variables to be taken into account.\n",
    "    </li>\n",
    "    <li><b>AR:</b> Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n",
    "    </li><li><b>MA: </b>Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n",
    "    </li></ul>\n",
    "    \n",
    "<br> Standard notation is used of VARMA(p,d,q)\n",
    "\n",
    "The parameters of the VARMA model are defined as follows:\n",
    "<ul>\n",
    "<li><b>p:</b> The number of lag observations included in the model, also called the lag order.\n",
    "</li><li><b>q:</b> The size of the moving average window, also called the order of moving average. </li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a04a72",
   "metadata": {},
   "source": [
    "## Cleanin Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read()\n",
    "df2 = pd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ecc0a",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ced92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average and standard deviation \n",
    "avg1 , dev1 = df1.mean(), df1.std()\n",
    "avg2 , dev2 = df2.mean(), df2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (df1 - avg1)/dev1\n",
    "df2 = (df2 - avg2)/dev2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524367b",
   "metadata": {},
   "source": [
    "### Dealing with staionary issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7eee30",
   "metadata": {},
   "source": [
    "1. Take the first difference, fixes it around zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.diff().dropna() #drops the value before the first vaule\n",
    "df2 = df2.diff().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ec0a6",
   "metadata": {},
   "source": [
    "2. Dealing with the increasing volatlity problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21871fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the standard deviation within each year\n",
    "#divde each month by the standard deviation of its year\n",
    "anual_volatility1 = df1.groupby(df1.index.year).std()\n",
    "anual_volatility2 = df2.groupby(df2.index.year).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d86df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forms a series thats the same length of the daa but calucate the standard devation of the year for that data point\n",
    "df2_annual_vol = df2.index.map(lambda d: anual_volatility1.loc[d.year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2 /df2_annual_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f6943",
   "metadata": {},
   "source": [
    "### Removing Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7a84b1",
   "metadata": {},
   "source": [
    "Here we get the average of the data point each year.Then we create a time series of the same lenght where the average. We then take the current series then subtract this average.\n",
    "\n",
    "To change to fit our data we would use quarters instead of months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e703703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of months \n",
    "month_avgs1 = df1.groupby(df1.index.month).mean()\n",
    "month_avgs2 = df2.groupby(df2.index.month).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a time series as the same length as our data\n",
    "df1_month_avgs = df1.index.map(lambda d: months_avgs1.loc[d.month])\n",
    "df2_month_avgs = df2.index.map(lambda d: months_avgs2.loc[d.month])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtract monthly data from currect data\n",
    "df1 = df1 - df1_month_avgs\n",
    "df2 = df2 - df2_month_avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b6dc4",
   "metadata": {},
   "source": [
    "We can then do test such as the Dickey fuller test or a unit root test to see if true is truely staionary. <br> This is ow appropriate to feed into VARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628883e",
   "metadata": {},
   "source": [
    " ## VAR\n",
    " \n",
    " Before going straight to VARIMA I am going to implement VAR to gather an inital understanding.\n",
    " <br> First theres two components we need to think about the first is getting the lag for the time series we are trying to predict (EBITDA) and the other time series (Shipping, Geographical, Operational Cost ...) that are used in our prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d149b03",
   "metadata": {},
   "source": [
    "In this example\n",
    "<br> df1 -->time series we are trying to predict --> EBITDA\n",
    "<br> df2 -->time series helping our prediction   --> Shipping Costs, Geogrphical, Operational Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df99056",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_pacf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LUKEBE~1\\AppData\\Local\\Temp/ipykernel_23912/814988379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## PACF - partical AutoCorrelation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_pacf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_pacf' is not defined"
     ]
    }
   ],
   "source": [
    "## PACF - partical AutoCorrelation \n",
    "plot_pacf(df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ed8a7",
   "metadata": {},
   "source": [
    "Getting the correlation between df1 and df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab468455",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LUKEBE~1\\AppData\\Local\\Temp/ipykernel_23912/4268716957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#lag in this example is the months\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mlagged_df1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Lag: %s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "#shows all lags between 1-14 and printing their corelation and p-value between the two\n",
    "#lag in this example is the months\n",
    "for lag in range(1,14):\n",
    "    df2 = df2.iloc[lag:]\n",
    "    lagged_df1 = df1.iloc[:-lag]\n",
    "    print('Lag: %s'%lag)\n",
    "    print(pearsonr(df2,lagged_df1))\n",
    "    print('----------')\n",
    "\n",
    "#Look for the smallest p value and the largest coreelation \n",
    "#1 lag = 1 time period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b117bc",
   "metadata": {},
   "source": [
    "Fitting VAR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa9545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the relavant columns\n",
    "df = df[[df1_column, df2_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_model =VAR(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cfe46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_fit = model.fit(maxlags = 13) # we use 13 for BOTH time series, Change depending on the lag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f961176",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_fit.summary()\n",
    "#gives a table of results, we have not specified a heater. It treats them equally, there for we have two tabels below.\n",
    "#Treats the two as the main series we want to predict\n",
    "#Look down the prob coloum where is it small (<0.5), the lags in this category should tell us what lags are \n",
    "#important (We already knwo this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf91d40",
   "metadata": {},
   "source": [
    "So the <b>VAR model</b> is \n",
    "\n",
    "Gather the coeficients aboove associated with their lags.\n",
    "\n",
    "i.e.\n",
    "<br><b>1st_coef = coefient above that links to the first lag that its probability is below 0.5</b>\n",
    "<br><b>1st_lag =  lets say 3 lag is the first lag with probability below 0.5, then we would get the data pinot from 3 periods ago</b>\n",
    "\n",
    "<br>\n",
    "<center><b>y_hat</b> = 1st_coef*1st_lag + 2nd_coef*2nd_lag + 3rd_coef*3rd_lag + ....</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c335d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be1fdc43",
   "metadata": {},
   "source": [
    "Calculate the errors. Absolute difference and Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ddfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b21488a5",
   "metadata": {},
   "source": [
    "\n",
    "## VARMA\n",
    "\n",
    "Adding the moving average to the VAR model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a27c33",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\LUKEBE~1\\AppData\\Local\\Temp/ipykernel_23912/2881045419.py\", line 2, in <module>\n",
      "    plot_pacf(df2)\n",
      "NameError: name 'df2' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"G:\\Anaconda\\envs\\pythonProject1\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\LUKEBE~1\\AppData\\Local\\Temp/ipykernel_23912/2881045419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#PACF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_pacf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mG:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2063\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NameError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#PACF for the Autoregression p value\n",
    "plot_pacf(df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590ba5e",
   "metadata": {},
   "source": [
    "Adding the moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716aab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF for the Moving Average q value\n",
    "plot_acf(df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Coloums want to use \n",
    "df_VARMA = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make model\n",
    "#order=(AR p value, MA q value)\n",
    "VARMA_model = VARMAX(df_VARMA, order=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7aa419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Model\n",
    "VARMA_fit = VARMA_model.fit()\n",
    "print(VARMA_fit.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39443f",
   "metadata": {},
   "source": [
    "Model for VARMA\n",
    "\n",
    "we will used the VARMAX.predict() then VARMAX.plot() functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
