{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6392a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "G:\\Anaconda\\envs\\pythonProject1\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.api import VAR\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a63cb",
   "metadata": {},
   "source": [
    "# VARIMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedcde6",
   "metadata": {},
   "source": [
    "<b>Referes to</b> \n",
    "<ul>\n",
    "    <li><a>https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/ </a></li>\n",
    "    <li><a>https://youtu.be/7_Js8h709Dw</a></li>\n",
    "    <li><a>https://youtu.be/6Ye0CsfRDJg</a></li>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7e7c8",
   "metadata": {},
   "source": [
    "Stands for Vector Autoregressive Intergrated Moving average <br>\n",
    "\n",
    "This acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n",
    "<ul>\n",
    "    <li><b>V:</b> Vector. Allows for multiple variables to be taken into account.\n",
    "    </li>\n",
    "    <li><b>AR:</b> Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n",
    "    </li><li><b>I:</b> Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n",
    "    </li><li><b>MA: </b>Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n",
    "    </li></ul>\n",
    "    \n",
    "<br> Standard notation is used of VARIMA(p,d,q)\n",
    "\n",
    "The parameters of the VARIMA model are defined as follows:\n",
    "<ul>\n",
    "<li><b>p:</b> The number of lag observations included in the model, also called the lag order.\n",
    "</li><li><b>d:</b> The number of times that the raw observations are differenced, also called the degree of differencing.\n",
    "    </li><li><b>q:</b> The size of the moving average window, also called the order of moving average. </li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a04a72",
   "metadata": {},
   "source": [
    "## Cleanin Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read()\n",
    "df2 = pd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ecc0a",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ced92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average and standard deviation \n",
    "avg1 , dev1 = df1.mean(), df1.std()\n",
    "avg2 , dev2 = df2.mean(), df2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (df1 - avg1)/dev1\n",
    "df2 = (df2 - avg2)/dev2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524367b",
   "metadata": {},
   "source": [
    "### Dealing with staionary issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7eee30",
   "metadata": {},
   "source": [
    "1. Take the first difference, fixes it around zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.diff().dropna() #drops the value before the first vaule\n",
    "df2 = df2.diff().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ec0a6",
   "metadata": {},
   "source": [
    "2. Dealing with the increasing volatlity problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21871fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the standard deviation within each year\n",
    "#divde each month by the standard deviation of its year\n",
    "anual_volatility1 = df1.groupby(df1.index+year).std()\n",
    "anual_volatility2 = df2.groupby(df2.index+year).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d86df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forms a series thats the same length of the daa but calucate the standard devation of the year for that data point\n",
    "df2_annual_vol = df2.index.map(lambda d: anual_volatility1.loc[d.year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2 /df2_annual_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f6943",
   "metadata": {},
   "source": [
    "### Removing Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e703703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of months \n",
    "month_avgs1 = df1.groupby(df1.index.month).mean()\n",
    "month_avgs2 = df2.groupby(df2.index.month).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a time series as the same length as our data\n",
    "df1_month_avgs = df1.index.map(lambda d: months_avgs1.loc[d.month])\n",
    "df2_month_avgs = df2.index.map(lambda d: months_avgs2.loc[d.month])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b6dc4",
   "metadata": {},
   "source": [
    "We can then do test such as the Dickey fuller test or a unit root test to see if true is truely staionary. <br> This is ow appropriate to feed into VARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628883e",
   "metadata": {},
   "source": [
    " ### VAR\n",
    " \n",
    " Before going straight to VARIMA I am going to implement VAR to gather an inital understanding.\n",
    " <br> First theres two components we need to think about the first is getting the lag for the time series we are trying to predict (EBITDA) and the other time series (Shipping, Geographical, Operational Cost ...) that are used in our prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27f523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d149b03",
   "metadata": {},
   "source": [
    "In this example\n",
    "<br> df1 -->time series we are trying to predict --> EBITDA\n",
    "<br> df2 -->time series helping our prediction   --> Shipping Costs, Geogrphical, Operational Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df99056",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_pacf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LUKEBE~1\\AppData\\Local\\Temp/ipykernel_23912/814988379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## PACF - partical AutoCorrelation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_pacf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_pacf' is not defined"
     ]
    }
   ],
   "source": [
    "## PACF - partical AutoCorrelation \n",
    "plot_pacf(df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ed8a7",
   "metadata": {},
   "source": [
    "Getting the correlation between df1 and df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab468455",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LUKEBE~1\\AppData\\Local\\Temp/ipykernel_23912/4268716957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#lag in this example is the months\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mlagged_df1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Lag: %s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "#shows all lags between 1-14 and printing their corelation and p-value between the two\n",
    "#lag in this example is the months\n",
    "for lag in range(1,14):\n",
    "    df2 = df2.iloc[lag:]\n",
    "    lagged_df1 = df1.iloc[:-lag]\n",
    "    print('Lag: %s'%lag)\n",
    "    print(pearsonr(df2,lagged_df1))\n",
    "    print('----------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
